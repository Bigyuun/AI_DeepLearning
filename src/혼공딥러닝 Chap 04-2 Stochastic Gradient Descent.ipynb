{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터 설정\n",
    "    \n",
    "    [http://bit.ly/perch_data](http://bit.ly/perch_data) 에서 데이터를 가져옵시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diagonal</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bream</td>\n",
       "      <td>242.0</td>\n",
       "      <td>25.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.5200</td>\n",
       "      <td>4.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bream</td>\n",
       "      <td>290.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>31.2</td>\n",
       "      <td>12.4800</td>\n",
       "      <td>4.3056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bream</td>\n",
       "      <td>340.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>31.1</td>\n",
       "      <td>12.3778</td>\n",
       "      <td>4.6961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bream</td>\n",
       "      <td>363.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>33.5</td>\n",
       "      <td>12.7300</td>\n",
       "      <td>4.4555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bream</td>\n",
       "      <td>430.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12.4440</td>\n",
       "      <td>5.1340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Species  Weight  Length  Diagonal   Height   Width\n",
       "0   Bream   242.0    25.4      30.0  11.5200  4.0200\n",
       "1   Bream   290.0    26.3      31.2  12.4800  4.3056\n",
       "2   Bream   340.0    26.5      31.1  12.3778  4.6961\n",
       "3   Bream   363.0    29.0      33.5  12.7300  4.4555\n",
       "4   Bream   430.0    29.0      34.0  12.4440  5.1340"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 링크에서 읽어오기\n",
    "fish = pd.read_csv('https://bit.ly/fish_csv_data')\n",
    "fish.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Species 열을 제외한 나머지 5개는 입력 데이터로 사용. Species 열은 타깃 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_input = fish[['Weight', 'Length', 'Diagonal', 'Height', 'Width']].to_numpy()\n",
    "fish_target = fish['Species'].to_numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사이킷런의 train_test_split() 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[0;32m      3\u001b[0m train_input, test_input, train_target, test_target \u001b[39m=\u001b[39m train_test_split(\n\u001b[0;32m      4\u001b[0m     fish_input, fish_target, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_input, test_input, train_target, test_target = train_test_split(\n",
    "    fish_input, fish_target, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 전처리 진행 ★★★"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m StandardScaler\n\u001b[0;32m      3\u001b[0m ss \u001b[39m=\u001b[39m StandardScaler()\n\u001b[0;32m      4\u001b[0m ss\u001b[39m.\u001b[39mfit(train_input)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(train_input)\n",
    "train_scaled = ss.transform(train_input)\n",
    "test_scaled = ss.transform(test_input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SGDClassifier 선언\n",
    "    \n",
    "    이는 2개의 매개변수가 필요하다.\n",
    "    - loss는 loss function의 종류를 지정 (여기서는 loss=’log’)\n",
    "    - max_iter은 epoch 횟수 지정 (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinear_model\u001b[39;00m \u001b[39mimport\u001b[39;00m SGDClassifier\n\u001b[0;32m      3\u001b[0m \u001b[39m# 사이킷런 1.1.0 버전 이하일 경우 'log_loss'를 'log'로 바꿀 것.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m sc \u001b[39m=\u001b[39m SGDClassifier(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlog_loss\u001b[39m\u001b[39m'\u001b[39m, max_iter\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# 사이킷런 1.1.0 버전 이하일 경우 'log_loss'를 'log'로 바꿀 것.\n",
    "sc = SGDClassifier(loss='log', max_iter=10, random_state=42)\n",
    "sc.fit(train_scaled, train_target)\n",
    "\n",
    "print(sc.score(train_scaled, train_target))\n",
    "print(sc.score(test_scaled, test_target))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 점진적 학습을 진행\n",
    "    \n",
    "    객체를 다시 만들지 말고 이미 훈련한 모델(sc)를 추가로 더 훈련해 보자. \n",
    "    \n",
    "    partial_fit()을 사용하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.partial_fit(train_scaled, train_target)\n",
    "\n",
    "print(sc.score(train_scaled, train_target))\n",
    "print(sc.score(test_scaled, test_target))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE\n",
    "아직 점수는 낮지만 epoch를 한 번 더 진행하니 정확도가 향상되기는 한다!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 과대 과소 적합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 사이킷런 1.1 버전에서는 SGDClassifier의 loss 매개변수 중 \n",
    "# 로지스틱 손실을 의미하는 'log'가 'log_loss'로 바뀐다는 경고가 발생합니다.\n",
    "# 사이킷런 1.1 이상을 사용하는 경우 loss='log'를 loss='log_loss'로 변경하세요.\n",
    "sc = SGDClassifier(loss='log', random_state=42)\n",
    "\n",
    "train_score = []\n",
    "test_score = []\n",
    "\n",
    "classes = np.unique(train_target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 300번의 epoch 진행.\n",
    "    \n",
    "    train과 test의 score는 매 epoch마다 저장하도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(0, 300):            # _는 나중에 사용하지 않고 그냥 버리는 값을 넣어두는 용도로 사용하는 파이썬의 특별한 변수임~\n",
    "    sc.partial_fit(train_scaled, train_target, classes=classes)\n",
    "    \n",
    "    train_score.append(sc.score(train_scaled, train_target))\n",
    "    test_score.append(sc.score(test_scaled, test_target))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 그래프로 score의 변화를 확인하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_score)\n",
    "plt.plot(test_score)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NOTE  \n",
    "    잘 보이지는 않지만… 약 100 epoch 이후에는 test 및 train dataset이 벌어지기 시작함을 볼 수 있다.\n",
    "    이 경우 약 100 epoch 만큼 학습하는 것이 적절해 보인다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 100 epoch로 학습 진행 후 score 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런 1.1 버전에서는 SGDClassifier의 loss 매개변수 중 \n",
    "# 로지스틱 손실을 의미하는 'log'가 'log_loss'로 바뀐다는 경고가 발생합니다.\n",
    "# 사이킷런 1.1 이상을 사용하는 경우 loss='log'를 loss='log_loss'로 변경하세요.\n",
    "sc = SGDClassifier(loss='log', max_iter=100, tol=None, random_state=42)\n",
    "sc.fit(train_scaled, train_target)\n",
    "\n",
    "print(sc.score(train_scaled, train_target))\n",
    "print(sc.score(test_scaled, test_target))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NOTE  \n",
    "\n",
    "    SGDClassifier는 일정 epoch 동안 성능이 향상되지 않으면 자동으로 학습을 중지한다.\n",
    "    tol 매개변수에서 향상될 최솟값을 지정할 수 있다. 위 코드는 tol=None으로 지정하여 자동으로 안 멈추고 지정한 epoch 횟수 만큼 학습을 진행 시킨 것이다.\n",
    "\n",
    "    참고로 SGDClassifier의 loss 매개변수에 대해서 기억할 것이 있다.\n",
    "    default로 ‘hinge’라는 알고리즘을 가지고 있다. 이는 SVM(Support Vector Machine)이라는 알고리즘을 활용한 것이다.\n",
    "    SVM은 굉장히 널리 사용되는 알고리즘이라는 것, 그리고 SGDClassifier는 loss 매개변수에 다양한 손실함수를 정의해줄 수 있다는 것을 기억하자."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21c37ab268b9e23b544a9f781756f80282062449103fada612b791dff0d8c44f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
